import math


def norm(vec):
    '''Return the norm of a vector stored as a dictionary'''

    sum_of_squares = 0.0
    for x in vec:
        sum_of_squares += vec[x] * vec[x]

    return math.sqrt(sum_of_squares)


def cosine_similarity(vec1, vec2):

    numerator = 0
    denominator_a = 0

    for value,elem1 in vec1.items():
        numerator += elem1*vec2.get(value,0.0)
        denominator_a += elem1**2

    denominator_b = 0

    for elem2 in vec2.values():

        denominator_b += elem2**2

    return numerator/((denominator_a*denominator_b)**(1/2))





def build_semantic_descriptors(sentences):

    semantic_descriptor = {}

    for sentence in sentences:
        distinct_words = []
        for word in sentence:
            if not word in distinct_words:
                distinct_words.append(word.lower())

        if len(distinct_words) > 1:

            for current_word in distinct_words:
                if current_word != "":
                    other_words = list(distinct_words)
                    other_words.remove(current_word)
                    if current_word in semantic_descriptor:

                        for other_word in other_words:

                            if other_word in semantic_descriptor[current_word]:
                                semantic_descriptor[current_word][other_word] += 1
                            else:
                                semantic_descriptor[current_word][other_word] = 1
                    else:
                        new_dictionary = {}
                        for other_word in other_words:
                            if other_word in new_dictionary:
                                new_dictionary[other_word] += 1

                            else:
                                new_dictionary[other_word] = 1

                            semantic_descriptor[current_word] = new_dictionary


    return semantic_descriptor



def build_semantic_descriptors_from_files(filenames):

    sentences = []

    for i in filenames:
        file_list = []

        file = open(i, "r", encoding="latin-1") #should i use utf-8
        file = file.read()
        file = file.lower()
        file = file.replace("!", ".")
        file = file.replace("?", ".")

        file = file.replace('"', " ")
        file = file.replace(",", " ")
        file = file.replace("-", " ")
        file = file.replace("--", " ")
        file = file.replace(":", " ")
        file = file.replace(";", " ")


        file_split = file.split(".")

        for sentence in file_split:
             file_list.append(sentence.split())

        sentences += file_list

    return build_semantic_descriptors(sentences)






def most_similar_word(word, choices, semantic_descriptors, similarity_fn):

    correct_option = choices[0]

    max_similarity = 0

    word = word.lower()

    for letters in range(len(choices)):
        choices[letters] = choices[letters].lower()

    if word not in semantic_descriptors:
        return correct_option

    for option in range(len(choices)):

        similarity = -1 if choices[option] not in semantic_descriptors else similarity_fn(semantic_descriptors[word], semantic_descriptors[choices[option]])

        max_similarity = similarity if (option == 0) else max_similarity

        if similarity > max_similarity:
            max_similarity = similarity
            correct_option = choices[option]

    return correct_option



def run_similarity_test(filename, semantic_descriptors, similarity_fn):

    correct = 0.0

    file = open(filename, "r", encoding="latin-1")
    file = file.read()
    file = file.lower()
    file = file.split("\n")

    list = []

    for item in file:
        if item != "":
           list.append(item.split())

    correct_answers = []

    for words in list:
        word_index = 0
        word = words[word_index]
        candindate_index = word_index + 1
        most_similar_word_candidate = words[candindate_index]
        choice_index = candindate_index + 1
        choices = words[choice_index:]

        most_similar_word_result = most_similar_word(word, choices, semantic_descriptors, similarity_fn)

        correct_answer = 1 if most_similar_word_result == most_similar_word_candidate else 0

        correct_answers.append(correct_answer)

    total_no_correct_answers = sum(correct_answers)

    return total_no_correct_answers/len(list)*100


